{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload the other files when they're changed\n",
    "# We'll not be using external files for this demo, but it's generally a good idea to keep these in the notebok\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "As in the slides, we'll be trying to fit a sine function with random error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies the seed for generation so it's deterministic\n",
    "np.random.seed(0)\n",
    "num_data = 9\n",
    "\n",
    "# Training data\n",
    "x = np.linspace(0,1,num=num_data)\n",
    "y = np.sin(2*np.pi*x) + np.random.randn(num_data)*0.15\n",
    "# Validation data\n",
    "xfit = np.linspace(0,1,1000)\n",
    "yfit = np.sin(2*np.pi*xfit)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for linear regression. If we want to use linear regression for polynomials, we need to first compute the polynomials.\n",
    "\n",
    "If we want to fit a n-th order polynomial, we first need to compute $x^n$, $x^{n-1}$, ..., $x^0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=3\n",
    "x_poly = np.zeros((num_data, M+1))\n",
    "for i in range(M+1):\n",
    "    x_poly[:,i] = x**i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we're using numpy's ``linalg`` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef,loss_train,_,_ = np.linalg.lstsq(x_poly, y, rcond=None)\n",
    "# Calculate training loss\n",
    "y_train = np.matmul(x_poly, coef)\n",
    "loss_train = np.mean((y_train-y)**2)\n",
    "\n",
    "xfit_poly = np.zeros((1000, M+1))\n",
    "for i in range(M+1):\n",
    "    xfit_poly[:,i] = xfit**i\n",
    "yfit_train = np.matmul(xfit_poly, coef)\n",
    "# Calculate validation loss\n",
    "loss_val = np.mean((yfit_train-yfit)**2)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yfit_train)\n",
    "print(\"Training loss: {0}; validation loss: {1}\".format(loss_train, loss_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase M and see the effect on training and validation loss\n",
    "M=3\n",
    "def train_lstsq_val(x, y, xfit, yfit, M):\n",
    "    num_data = np.shape(x)[0]\n",
    "    x_poly = np.zeros((num_data, M+1))\n",
    "    for i in range(M+1):\n",
    "        x_poly[:,i] = x**i\n",
    "    coef,_,_,_ = np.linalg.lstsq(x_poly, y, rcond=None)\n",
    "    # Calculate training loss\n",
    "    y_train = np.matmul(x_poly, coef)\n",
    "    loss_train = np.mean((y_train-y)**2)\n",
    "\n",
    "    num_data_val = np.shape(xfit)[0]\n",
    "    xfit_poly = np.zeros((num_data_val, M+1))\n",
    "    for i in range(M+1):\n",
    "        xfit_poly[:,i] = xfit**i\n",
    "    yfit_train = np.matmul(xfit_poly, coef)\n",
    "    # Calculate validation loss\n",
    "    loss_val = np.mean((yfit_train-yfit)**2)\n",
    "    return coef, loss_train, loss_val, yfit_train\n",
    "\n",
    "coef, loss_train, loss_val, yfit_train = train_lstsq_val(x, y, xfit, yfit, M)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yfit_train, 'r')\n",
    "print(\"Training loss: {0}; validation loss: {1}\".format(loss_train, loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validataion loss vs order M\n",
    "# Be reasonable with M size (Don't try something like 10,000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fighting overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the number of training data points and M. Pick M>=9 so that it was previously overfitting\n",
    "num_data = 9\n",
    "M = 9\n",
    "np.random.seed(0)\n",
    "x = np.linspace(0,1,num=num_data)\n",
    "y = np.sin(2*np.pi*x) + np.random.randn(num_data)*0.15\n",
    "coef, loss_train, loss_val, yfit_train = train_lstsq_val(x, y, xfit, yfit, M)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yfit_train, 'r')\n",
    "print(\"Training loss: {0}; validation loss: {1}\".format(loss_train, loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss vs order M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 regularization (penalizing large coefficients)\n",
    "\n",
    "More information can be found here: https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization\n",
    "\n",
    "(or if you just search for the term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify l2 value to increase strength of regularization. You may need very large l2 to see an effect\n",
    "num_data = 9\n",
    "M = 8\n",
    "l2 = 0\n",
    "def train_lstsq_val_l2(x, y, xfit, yfit, M, l2=0):\n",
    "    num_data = np.shape(x)[0]\n",
    "    # Adding L2 regularization for linear regression is equivalent to adding a data point [1,1,1,...] and let it fit to 0\n",
    "    # You will learn about it if you take any machine learning course\n",
    "    x_poly = np.zeros((num_data+1, M+1))\n",
    "    x_poly[-1] = l2*num_data\n",
    "    y_expand = np.zeros(num_data+1)\n",
    "    y_expand[:-1] = y\n",
    "    \n",
    "    for i in range(M+1):\n",
    "        x_poly[:-1,i] = x**i\n",
    "    coef,sth,_,_ = np.linalg.lstsq(x_poly, y_expand, rcond=None)\n",
    "    # Calculate training loss\n",
    "    y_train = np.matmul(x_poly, coef)\n",
    "    y_train = y_train[:-1]\n",
    "    loss_train = np.mean((y_train-y)**2)\n",
    "\n",
    "    num_data_val = np.shape(xfit)[0]\n",
    "    xfit_poly = np.zeros((num_data_val, M+1))\n",
    "    for i in range(M+1):\n",
    "        xfit_poly[:,i] = xfit**i\n",
    "    yfit_train = np.matmul(xfit_poly, coef)\n",
    "    # Calculate validation loss\n",
    "    loss_val = np.mean((yfit_train-yfit)**2)\n",
    "    return coef, loss_train, loss_val, yfit_train\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "x = np.linspace(0,1,num=num_data)\n",
    "y = np.sin(2*np.pi*x) + np.random.randn(num_data)*0.15\n",
    "coef, loss_train, loss_val, yfit_train = train_lstsq_val_l2(x, y, xfit, yfit, M, l2)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yfit_train, 'r')\n",
    "print(\"Training loss: {0}; validation loss: {1}\".format(loss_train, loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss vs regularization strength l2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
